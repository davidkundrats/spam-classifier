{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc265e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b3713ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"dataset/enron1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38116d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham = []\n",
    "spam = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3071e628",
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(data_path):\n",
    "    #in subdirectory\n",
    "    for file in files:\n",
    "        with open(os.path.join(root, file), 'r', encoding='latin1') as f:\n",
    "            content = f.read()\n",
    "            #if in ham, append ham \n",
    "            if 'ham' in root:\n",
    "                ham.append({'filename': file, 'content': content, 'label': 'ham'})\n",
    "            #if in spam, append spam\n",
    "            elif 'spam' in root:\n",
    "                spam.append({'filename': file, 'content': content, 'label': 'spam'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01ddcb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_df = pd.DataFrame(ham)\n",
    "spam_df = pd.DataFrame(spam)\n",
    "df = pd.concat([ham_df, spam_df], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7552d3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                             filename  \\\n",
      "0     1365.2000-06-16.farmer.ham.txt   \n",
      "1     3560.2001-02-09.farmer.ham.txt   \n",
      "2     0877.2000-04-06.farmer.ham.txt   \n",
      "3     2937.2000-11-27.farmer.ham.txt   \n",
      "4     1270.2000-06-07.farmer.ham.txt   \n",
      "...                              ...   \n",
      "5167     1505.2004-07-09.GP.spam.txt   \n",
      "5168     2148.2004-09-13.GP.spam.txt   \n",
      "5169     2406.2004-10-06.GP.spam.txt   \n",
      "5170     1459.2004-06-30.GP.spam.txt   \n",
      "5171     2030.2004-08-30.GP.spam.txt   \n",
      "\n",
      "                                                content label  \n",
      "0     Subject: revised sea robin availabilities effe...   ham  \n",
      "1     Subject: re : january spot purchases - deals n...   ham  \n",
      "2     Subject: re : buyback / deficiency deals works...   ham  \n",
      "3     Subject: king ranch processed volumes at tailg...   ham  \n",
      "4     Subject: confirming requisitions\\nconfirming t...   ham  \n",
      "...                                                 ...   ...  \n",
      "5167  Subject: what she doesnt know sprig bashaw\\ndi...  spam  \n",
      "5168  Subject: want to lose up to 19 % weight . try ...  spam  \n",
      "5169  Subject: buy cheap viagra through us .\\nhi ,\\n...  spam  \n",
      "5170  Subject: viewsonic airpanel vl 50 15 - inch sm...  spam  \n",
      "5171  Subject: entourage , stockmogul newsletter\\nra...  spam  \n",
      "\n",
      "[5172 rows x 3 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38676670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import PorterStemmer\n",
    "def preprocess(text): \n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.replace('\\n', ' ')\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    #stemmer = PorterStemmer()\n",
    "    #stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
    "    \n",
    "    return ' '.join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae8e2d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject 8 dear friend size 1 order confirmation order shipped january via fedex federal express tracking number 45954036 thank registering userid 56075519 learn make fortune ebay complete turnkey system software videos turorials clk information clilings\n"
     ]
    }
   ],
   "source": [
    "df['preprocessed_content'] = df['content'].apply(preprocess)\n",
    "print(df.iloc[4000]['preprocessed_content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4be363bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def train(X, y, model):\n",
    "    vectorizer = CountVectorizer()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = .2, random_state= 42)\n",
    "    X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "    X_test_vectorized = vectorizer.transform(X_test) \n",
    "    model.fit(X_train_vectorized, y_train)\n",
    "    print(f'Model trained. Model Accuracy: {model.score(X_test_vectorized, y_test)}')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "53b74f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained. Model Accuracy: 0.9487922705314009\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "X = df['preprocessed_content']\n",
    "y= df['label']\n",
    "model = train(X, y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4713e0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
